{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cse450_prove02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnzR6GewlGqt+vMkno0V+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexjohnson21/ubiquitous-sniffle/blob/master/cse450_prove02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyqfSe7jZx4W",
        "colab_type": "text"
      },
      "source": [
        "# Prove 02 - kNN Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zls0nUeqaEWz",
        "colab_type": "text"
      },
      "source": [
        "## Initial setup\n",
        "Using the code provided in the assignment description, we will read the CSV straight from the course github into a variable and use it from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phPI8QSDUY4P",
        "colab_type": "code",
        "outputId": "de3ba490-edd0-4ece-c0b3-96bf4459600d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import collections\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KDTree\n",
        "\n",
        "# URL Still current despite the official course code change\n",
        "url = \"https://byui-cs.github.io/cs450-course/week01/iris.data\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Make sure we got what we needed\n",
        "print(data)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSEusnnnc29T",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the data into \"features\" and \"target\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fSiX8Kqaa2l",
        "colab_type": "code",
        "outputId": "4a1608a5-8601-4675-bc67-49f1606ae5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Perform a split from \"all\" to \"all minus 1\" (first to last -1) to get features\n",
        "features = data.iloc[:, :-1].to_numpy()\n",
        "\n",
        "# Perform a split on just the last element to get data\n",
        "targets = data.iloc[:, -1].to_numpy()\n",
        "\n",
        "# Sanity check\n",
        "## print(features, '\\n\\n\\n', target)\n",
        "print(np.size(features, 0))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeMRNKmZe2FV",
        "colab_type": "text"
      },
      "source": [
        "## Passing the feature and target arrays to *test_train_split*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-JX72IUgm6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taken from the assignment description on the course Github\n",
        "\n",
        "# Randomize and split the samples into two groups. \n",
        "# 30% of the samples will be used for testing.\n",
        "# The other 70% will be used for training.\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(features, targets, test_size=.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293BmC9klu73",
        "colab_type": "text"
      },
      "source": [
        "## Creating a hardcoded classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ybY1wSpl_Eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HardCodedClassifier:\n",
        "  # Default constructor\n",
        "  def __init__(self):\n",
        "    self.features = None\n",
        "    self.targets = None\n",
        "    self.predictions = None\n",
        "  \n",
        "  # fit - trains the classifier\n",
        "  def fit(self, features, targets):\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "  \n",
        "  # predict - makes predictions based on the training (hardcoded for now)\n",
        "  def predict(self, test_features):\n",
        "    self.predictions = np.array(['Iris-setosa'] * np.size(test_features, 0))\n",
        "    return self.predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFK77rbMnJyI",
        "colab_type": "text"
      },
      "source": [
        "## Creating a kNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3HgO-dQnM40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I learned about list comprehension after I implemented the predict and predict_row\n",
        "# methods. I might update them to be more elegant with list comprehension in the\n",
        "# future.\n",
        "\n",
        "class KnnClassifier:\n",
        "  # Default Constructor\n",
        "  def __init__(self):\n",
        "    self.features = None\n",
        "    self.targets = None\n",
        "    self.predictions = None\n",
        "  \n",
        "  # fit - trains the classifier\n",
        "  def fit(self, features, targets):\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "  \n",
        "  def calc_distance(self, x1, x2):\n",
        "    return np.sqrt((x1[0] - x2[0]) **2 + (x1[1] - x2[1]) **2)\n",
        "\n",
        "  # predict - makes predictions based on the training\n",
        "  def predict(self, test_data, k):\n",
        "    predictions = []\n",
        "    for row in test_data:\n",
        "      predictions += [self.predict_row(row, k)]\n",
        "    return predictions\n",
        "\n",
        "  # predict_row - helper function to predict a single entity in test_data\n",
        "  def predict_row(self, row, k):\n",
        "    distances = []\n",
        "    for feature in self.features:\n",
        "      distances += [self.calc_distance(row, feature)]\n",
        "    indices = np.argsort(distances)[0:k]\n",
        "    return collections.Counter(self.targets[indices]).most_common(1)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBSZbUWf6pNb",
        "colab_type": "text"
      },
      "source": [
        "## Instantiate a KnnClassifier and test its accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlqrLUbW2H7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10a5c34e-5f81-4fe9-8a01-0144031a8f86"
      },
      "source": [
        "# Terrible naming scheme, but it's quick...\n",
        "\n",
        "knc = KnnClassifier()\n",
        "knc.fit(train_data, train_targets)\n",
        "\n",
        "knc_predictions = knc.predict(test_data, 10)\n",
        "\n",
        "accuracy_knc = accuracy_score(test_targets, knc_predictions)\n",
        "accuracy_knc"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttwp9PEx62FA",
        "colab_type": "text"
      },
      "source": [
        "## Instantiate and experiment with a SKLearn KNeighborsClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJpbe6Am7FTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d42a752-a327-40ab-e39a-6e85dcf6c580"
      },
      "source": [
        "# Terrible naming scheme, but it's quick...\n",
        "\n",
        "KNC = KNeighborsClassifier(n_neighbors=3)\n",
        "KNC.fit(train_data, train_targets)\n",
        "KNC_predictions = KNC.predict(test_data)\n",
        "\n",
        "accuracy_KNC = accuracy_score(test_targets, KNC_predictions)\n",
        "accuracy_KNC"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKpfgQAf8-Eo",
        "colab_type": "text"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "The SciKit-Learn KNN classifier works very well. Its accuracy fluctuates between 0.87 and 1.00 pretty consistently. The accuracy of my own classifier fluctuates between 0.60 and 0.85. The SKLearn version is clearly written much better and leaves anything I could write in the dust."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEaj-nl39rQJ",
        "colab_type": "text"
      },
      "source": [
        "## BONUS: Experimenting with a KD Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD4LTGKA948L",
        "colab_type": "text"
      },
      "source": [
        "### Set up the KDTree and run some tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISmSvfEp-Fph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1145c05-2075-468f-f318-3c209717f15d"
      },
      "source": [
        "# Again, not a good naming scheme. But it's quick.\n",
        "\n",
        "# Reference used: scikit-learn docs at \n",
        "#   https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
        "\n",
        "kdt = KDTree(train_data, leaf_size=2)\n",
        "dist, ind = kdt.query(test_data, k=3)\n",
        "kdt_predictions = []\n",
        "\n",
        "for value in train_targets[ind]:\n",
        "  kdt_predictions += [collections.Counter(value).most_common(1)[0][0]]\n",
        "\n",
        "# kdt_predictions\n",
        "\n",
        "accuracy_kdt = accuracy_score(test_targets, kdt_predictions)\n",
        "\n",
        "accuracy_kdt"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cff96l9cBSu8",
        "colab_type": "text"
      },
      "source": [
        "### Further conclusions\n",
        "\n",
        "The KDTree is much more accurate than even the sklearn KNearestNeighbors classifier. Accuracy fluctuates anywhere from 0.91 to 1.00, with a high frequency of 1.00. I have little to no idea as to the best classification algorithms. However, even in this assignment, I've seen that there are probably a lot of well-written classifiers that may have different benefits in different situations."
      ]
    }
  ]
}