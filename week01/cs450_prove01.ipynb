{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs450-prove01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKhgvGS7YPTvjDrRflobF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexjohnson21/ubiquitous-sniffle/blob/master/cs450_prove01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyqfSe7jZx4W",
        "colab_type": "text"
      },
      "source": [
        "# Prove 01 - Classifier Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zls0nUeqaEWz",
        "colab_type": "text"
      },
      "source": [
        "## Initial setup\n",
        "Using the code provided in the assignment description, we will read the CSV straight from the course github into a variable and use it from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phPI8QSDUY4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "e7d11da9-5d4a-43c1-fee0-a6a21658e5af"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# URL Still current despite the official course code change\n",
        "url = \"https://byui-cs.github.io/cs450-course/week01/iris.data\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Make sure we got what we needed\n",
        "print(data)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width         species\n",
            "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
            "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
            "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
            "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
            "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
            "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
            "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
            "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
            "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSEusnnnc29T",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the data into \"features\" and \"target\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fSiX8Kqaa2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29f983d9-da25-4b16-cfda-a2dd1ad3c26c"
      },
      "source": [
        "# Perform a split from \"all\" to \"all minus 1\" (first to last -1) to get features\n",
        "features = data.iloc[:, :-1].to_numpy()\n",
        "\n",
        "# Perform a split on just the last element to get data\n",
        "targets = data.iloc[:, -1].to_numpy()\n",
        "\n",
        "# Sanity check\n",
        "## print(features, '\\n\\n\\n', target)\n",
        "print(np.size(features, 0))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeMRNKmZe2FV",
        "colab_type": "text"
      },
      "source": [
        "## Passing the feature and target arrays to *test_train_split*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-JX72IUgm6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taken from the assignment description on the course Github\n",
        "\n",
        "# Randomize and split the samples into two groups. \n",
        "# 30% of the samples will be used for testing.\n",
        "# The other 70% will be used for training.\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(features, targets, test_size=.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN1Ptt3Hg-Ie",
        "colab_type": "text"
      },
      "source": [
        "## Creating and teaching a Naive Bayesian classifier with our data\n",
        "(and verifying the accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8OsfDWehGn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2668cbc-3b4b-4a94-88bc-038f2de2dc07"
      },
      "source": [
        "# Partially taken from the assignment description on course Github\n",
        "\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(train_data, train_targets)\n",
        "\n",
        "targets_predicted = classifier.predict(test_data)\n",
        "\n",
        "accuracy = accuracy_score(test_targets, targets_predicted)\n",
        "print(accuracy)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293BmC9klu73",
        "colab_type": "text"
      },
      "source": [
        "## Creating a hardcoded classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ybY1wSpl_Eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HardCodedClassifier:\n",
        "  # Default constructor\n",
        "  def __init__(self):\n",
        "    self.features = None\n",
        "    self.targets = None\n",
        "    self.predictions = None\n",
        "  \n",
        "  # fit - trains the classifier\n",
        "  def fit(self, features, targets):\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "  \n",
        "  # predict - makes predictions based on the training (hardcoded for now)\n",
        "  def predict(self, test_features):\n",
        "    self.predictions = np.array(['Iris-setosa'] * np.size(test_features, 0))\n",
        "    return self.predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPELZCR0vKC1",
        "colab_type": "text"
      },
      "source": [
        "## Test an instance of the hardcoded classifer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIm3hyFfqRZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "b28bf8ea-e58f-4c8e-d5f3-ee78562f68a6"
      },
      "source": [
        "hcc = HardCodedClassifier()\n",
        "hcc.fit(train_data, train_targets)\n",
        "\n",
        "hcc_predictions = hcc.predict(test_data)\n",
        "\n",
        "# Sanity check\n",
        "print(hcc.predictions, '\\n', np.size(hcc.predictions))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'] \n",
            " 45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Min6KZJtvmp4",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy of hardcoded classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4oe_D-evBaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d92fbb68-6149-48c9-eea8-1fdb45d1b993"
      },
      "source": [
        "hcc_accuracy = accuracy_score(test_targets, hcc_predictions)\n",
        "print(hcc_accuracy)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}